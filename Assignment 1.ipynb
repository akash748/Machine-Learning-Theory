{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1:What does one mean by the term &quot;machine learning&quot;?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed.The primary aim is to allow the computers learn automatically without human intervention or assistance and adjust actions accordingly.\n",
    "The term basically means learning the paramters of the mathematical equations in such a way that it minimizes the error in our prediction and the actual value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Linear Reg gif.gif\" width = 450px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Can you think of 4 distinct types of issues where it shines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four Distinct types of issues where machine learning shines is :\n",
    "\n",
    "1) Classification :- Suppose we want to classify whether a book is worth reading or not based on certain inputs. Machine learning will make such jobs easier as it will become impossible for a human being to do this task manually if the number of books is lets say 1 million !\n",
    "\n",
    "2) Regression :- Suppose we want to predict the price of a house based on certain inputs. We can achieve this task with the help of machine learning with ease.\n",
    "\n",
    "3) Anamoly Detection :- The different techniques available in machine learning can help us to identify whether a certain transaction made is fraudulent or not subject to if we feed the correct data.\n",
    "\n",
    "4) Clustering :- This helps us to find the structure in the data. This type of machine learning techniques falls under the belt of unsupervised machine learning where we are provided with the unlabelled data. For example Customer Segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3:What is a labeled training set, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeled data is a group of samples that have been tagged with one or more labels. Labeling typically takes a set of unlabeled data and augments each piece of it with informative tags. For example, a data label might indicate whether a photo contains a horse or a cow, which words were uttered in an audio recording, what type of action is being performed in a video, what the topic of a news article is, what the overall sentiment of a tweet is, or whether a dot in an X-ray is a tumor.\n",
    "\n",
    "\n",
    "Labels can be obtained by asking humans to make judgments about a given piece of unlabeled data. Labeled data is significantly more expensive to obtain than the raw unlabeled data.\n",
    "\n",
    "Labelled data forms the basis of supervised machine learning algorithms.\n",
    "\n",
    "In labelled data the output is known and our model tries to learn from it to apply it in the future unknown cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4:What are the two most important tasks that are supervised?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two most important tasks that are supervised are :\n",
    "\n",
    "1) Classification - Here the dependent feature is discrete\n",
    "\n",
    "2) Regression - Here the dependent feature is continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5:Can you think of four examples of unsupervised tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four examples of unsupervised tasks are :-\n",
    "\n",
    "1)Customer Segmentation\n",
    "\n",
    "2)Biology - for genetic and species grouping\n",
    "\n",
    "3)Medical imaging - for distinguishing between different kinds of tissues\n",
    "\n",
    "4)Market research - for differentiating groups of customers based on some attributes\n",
    "\n",
    "5)Recommender systems - giving you better Amazon purchase suggestions or Netflix movie matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6:State the machine learning model that would be best to make a robot walk through various\n",
    "unfamiliar terrains?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make the robot walk through various unfamiliar terrains with the help of reinforcement learning.\n",
    "\n",
    "Reinforcement learning is an area of Machine Learning. It is about taking suitable action to maximize reward in a particular situation. It is employed by various software and machines to find the best possible behavior or path it should take in a specific situation. Reinforcement learning differs from the supervised learning in a way that in supervised learning the training data has the answer key with it so the model is trained with the correct answer itself whereas in reinforcement learning, there is no answer but the reinforcement agent decides what to do to perform the given task. In the absence of a training dataset, it is bound to learn from its experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7:Which algorithm will you use to divide your customers into different groups?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use various algorithms for customer segmentation namely K means clustering , DBSCAN and Hierarchical clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8:Will you consider the problem of spam detection to be a supervised or unsupervised learning\n",
    "problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A spam detection is a classic supervised learning problem. But most of us get confused with anomoly detection problem(which is unsupervised learning using algorithms like ). For example, finding out the defective parts produced by an aircraft industry.\n",
    "\n",
    "\n",
    "\n",
    "The key difference is that in anomoly detection problem we tend to have lot of positive data and very few negative data and also even though you learn about the defective products today, you are more likely to face an anomaly tomorrow with different features. On the contrary, in spam detection we have almost enough of equal number of positive and negative examples to train. Multivariate Gaussian distribution can be used for anomoly detection algorithm and SVM, desicion trees, Neural networks etc are used for supervised learning.\n",
    "\n",
    "\n",
    "\n",
    "Examples for anomoly detection:\n",
    "\n",
    "\n",
    "Fraud detection\n",
    "\n",
    "Cyber attack detection\n",
    "\n",
    "Monitoring machines in data center\n",
    "\n",
    "Examples for supervised learning :\n",
    "\n",
    "\n",
    "Cancer classification\n",
    "\n",
    "Email spam classification\n",
    "\n",
    "Weather prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 9:What is the concept of an online learning system?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is being generated in huge quantities everywhere. Twitter generates 12 + TB of data every day, Facebook generates 25 + TB of data everyday and Google generates much more than these quantities everyday. Given that such data is being produced everyday, we need to build tools to handle data with high\n",
    "\n",
    "1. Volume : High volume of data are stored today for any industry. Conventional models on such huge data are infeasible.\n",
    "\n",
    "\n",
    "2. Velocity : Data come at high speed and demand quicker learning algorithms.\n",
    "\n",
    "\n",
    "3. Variety : Different sources of data have different structures. All these data contribute to prediction. A good algorithm can take in such variety of data.\n",
    "\n",
    "\n",
    "A simple predictive algorithm like Random Forest on about 50 thousand data points and 100 dimensions take 10 minutes to execute on a 12 GB RAM machine. Problems with hundreds of millions of observation is simply impossible to solve using such machines. Hence, we are left with only two options : Use a stronger machine or change the way a predictive algorithm works. First option is not always feasible. In this article we will learn about On-line Learning algorithms which are meant to handle data with such high Volume and Velocity with limited performance machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In such type of machine learning algorithms we use the training sample once each only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 10:What is out-of-core learning, and how does it differ from core learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term out-of-core typically refers to processing data that is too large to fit into a computer’s main memory.\n",
    "\n",
    "\n",
    "Typically, when a dataset fits neatly into a computer’s main memory, randomly accessing sections of data has a (relatively) small performance penalty.\n",
    "\n",
    "\n",
    "When data must be stored in a medium like a large spinning hard drive or an external computer network, it becomes very expensive to randomly seek to an arbitrary section of data or to process the same data multiple times.\n",
    "\n",
    "\n",
    "\n",
    "In such a case, an out-of-core algorithm would try to access all relevant data in one sequence.\n",
    "\n",
    "\n",
    "However, modern computers have a deep memory hierarchy, and replacing random access with sequential access can increase performance even on datasets that fit within memory\n",
    "\n",
    "Core Learning is when the entire data can be fitted into ram for processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 11:What kind of learning algorithm makes predictions using a similarity measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning algorithm that relies on a similarity measure to make predictions is instance-based algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 12.What&#39;s the difference between a model parameter and a hyperparameter in a learning\n",
    "algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model parameter is a configuration variable that is internal to the model and whose value can be estimated from data.\n",
    "\n",
    "\n",
    "They are required by the model when making predictions.\n",
    "\n",
    "They values define the skill of the model on your problem.\n",
    "\n",
    "They are estimated or learned from data.\n",
    "\n",
    "They are often not set manually by the practitioner.\n",
    "\n",
    "They are often saved as part of the learned model.\n",
    "\n",
    "Some examples of model parameters include:\n",
    "\n",
    "The weights in an artificial neural network.\n",
    "\n",
    "The support vectors in a support vector machine.\n",
    "\n",
    "The coefficients in a linear regression or logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model hyperparameter is a configuration that is external to the model and whose value cannot be estimated from data.\n",
    "\n",
    "\n",
    "They are often used in processes to help estimate model parameters.\n",
    "\n",
    "They are often specified by the practitioner.\n",
    "\n",
    "They can often be set using heuristics.\n",
    "\n",
    "They are often tuned for a given predictive modeling problem.\n",
    "\n",
    "Some examples of model hyperparameters include:\n",
    "\n",
    "\n",
    "The learning rate for training a neural network.\n",
    "\n",
    "The C and sigma hyperparameters for support vector machines.\n",
    "\n",
    "The k in k-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 13:What are the criteria that model-based learning algorithms look for? What is the most popular\n",
    "method they use to achieve success? What method do they use to make predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model based learning algorithm search for the optimal value of parameters in a model that will give the best results for the new instances. We often use a cost function or similar to determine what the parameter value has to be in order to minimize the function. The model makes prediction by using the value of the new instance and the parameters in its function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questioon 14:Can you name four of the most important Machine Learning challenges?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four biggest challenges in machine learning are the problems of overfitting(low bias and high variance), underfitting (high bias and low variance), inadequate quality of data and inadequate quantity of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 15.What happens if the model performs well on the training data but fails to generalize the results\n",
    "to new situations? Can you think of three different options?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model performs well on the training data but fails to generalize the results in the test data then it is the case of overfitiing. Three methods that can be used to reduce overfitting are using more training data, using regularization techniques and removing the reduntant features in the training data or also using a simpler model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 16.What exactly is a test set, and why would you need one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you test the accuracy of your model on the same training set which you used to create the model then it is obvious that you will get a very high accuracy. Does that mean your model is ready to be deployed. It is very natural for a model to perform well on the data it has been trained upon. We need a model that performs well on the unseen data as well. Thus to test our models performance before deployement we use the test data which is the unseen data and use its accuracy to come to a conclusion regarding the models performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 17.What is a validation set&#39;s purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Dataset: The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. The evaluation becomes more biased as skill on the validation dataset is incorporated into the model configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 18.What precisely is the train-dev kit, when will you need it, how do you put it to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the training, development (dev) and test sets has a huge impact on productivity. It is important to choose the dev and test sets from the same distribution and it must be taken randomly from all the data.\n",
    "\n",
    "Guideline: Choose a dev set and test set to reflect data you expect to get in the future.\n",
    "\n",
    "The size of the dev and test set should be big enough for the dev and test results to be representative of the performance of the model. If the dev set has 100 examples, the dev accuracy can vary a lot depending on the chosen dev set. For bigger datasets (>1M examples), the dev and test set can have around 10,000 examples each for instance (only 1% of the total data).\n",
    "\n",
    "Guideline: The dev and test sets should be just big enough to represent accurately the performance of the model\n",
    "\n",
    "If the training set and dev sets have different distributions, it is good practice to introduce a train-dev set that has the same distribution as the training set. This train-dev set will be used to measure how much the model is overfitting. Again, refer to the course content for a full overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 19.What could go wrong if you use the test set to tune hyperparameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you tune hyperparameters using the test sets, then it may not perform well on the out-of-sample data because the model is tuned just for that specific set.Also it will give us a fake faith that our model is performing very well since the model will be tuned based on test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
