{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1:Explain the term machine learning, and how does it work? Explain two machine learning\n",
    "applications in the business world. What are some of the ethical concerns that machine learning\n",
    "applications could raise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is a data analytics technique that teaches computers to do what comes naturally to humans and animals: learn from experience. Machine learning algorithms use computational methods to “learn” information directly from data without relying on a predetermined equation as a model. The algorithms adaptively improve their performance as the number of samples available for learning increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two applications are fraud detection and customer churn modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first set of issues consists of those that arise from the features of machine learning. Many of the machine learning techniques that led to the current success of AI are based on artificial neural networks. The features of these approaches that give rise to ethical concerns are opacity, unpredictability and the need for large datasets to train the technologies. Neither the developer, the deployer nor the user (see box) can normally know in advance how the system will react to a given set of inputs. And because the system learns and is thus adaptive and dynamic, past behaviours are not a perfect predictor for future behaviour in identical situations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2:Provide a few examples of various types of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Learning is a method that involves learning using labeled past data and the algorithm shall predict the label for unseen or future data. A supervised machine learning algorithm is actually told what to look for, and so it does until it finds the underlying patterns that yield the expected output to a satisfactory degree of accuracy. In other words, using these prior known outputs, the machine learning algorithm learns from the past data and then generates an equation for the label or the value. The application of supervised machine learning is classification and regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Segmentation – where various image classification actions are performed using image data and pre-identified labels that we are looking for.\n",
    "Medical Diagnosis – by making use of medical imagery and past labeled data which contains labels for disease conditions, we can identify a disease for the new patients.\n",
    "Fraud Detection – classification algorithms can be used to detect fraud transactions, fraud customers, etc. using historic data to identify the patterns that can lead to possible fraud.\n",
    "Spam detection – again, classification algorithms are leveraged to classify an email as safe or as spam.\n",
    "Speech Recognition – The algorithm is trained with voice data and various identifications can be done using the same, such as voice-activated passwords, voice commands, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key application area of Unsupervised Learning is all about “advanced” exploratory data analysis. One can see that being applied on various domains and data.\n",
    "\n",
    "Network Analysis: Used in document Network Analysis of text data for identifying plagiarism and copyrights in various scientific documents and scholarly articles.\n",
    "Recommendation Systems: Widely used in recommendation systems for various web applications and e-Commerce websites.\n",
    "X-ray Crystallography: Used to categorize the protein structure of a certain protein and to determine its interactions with other proteins in the strands.\n",
    "Social Sciences: Clustering in Social Network Analysis is implemented by DBSCAN where objects (points) are clustered based on object’s linkage rather than similarity.\n",
    "Search Engine: where objects that are similar to each other must be presented together and dissimilar objects should be ignored. Also, it is required to fetch objects that are closely related to a search term, if not completely related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinforcement Learning is best used in cases where the application scenario is known, along with the best possible as well as unwanted outcomes but it is impossible to build any feasible mathematical model using supervised learning nor finding similarities can help solve any problems. Some of the best application of Reinforcement Learning are:\n",
    "\n",
    "Dynamic Pricing – a method by which prices are adjusted based on supply and demand, so as to maximize the revenue and sales. Q-learning is majorly used for pricing models.\n",
    "Industrial Automation using Robotics\n",
    "Advanced training and learning environment in academics and vocational training like pilot training, train driver simulations, etc.\n",
    "Gaming Solutions and logic, where most of the in-game logic can be defined using reinforcement learning.\n",
    "Optimizing Delivery routes and finding the best possible routes for last point delivery.\n",
    "Financial investment decisions for finding out the best possible trading strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3:Examine the various forms of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are perhaps 14 types of learning that you must be familiar with as a machine learning practitioner; they are:\n",
    "\n",
    "Learning Problems\n",
    "\n",
    "1. Supervised Learning\n",
    "2. Unsupervised Learning\n",
    "3. Reinforcement Learning\n",
    "Hybrid Learning Problems\n",
    "\n",
    "4. Semi-Supervised Learning\n",
    "5. Self-Supervised Learning\n",
    "6. Multi-Instance Learning\n",
    "Statistical Inference\n",
    "\n",
    "7. Inductive Learning\n",
    "8. Deductive Inference\n",
    "9. Transductive Learning\n",
    "Learning Techniques\n",
    "\n",
    "10. Multi-Task Learning\n",
    "11. Active Learning\n",
    "12. Online Learning\n",
    "13. Transfer Learning\n",
    "14. Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4:Can you explain what a well-posed learning problem is? Explain the main characteristics that must\n",
    "be present to identify a learning problem properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Well Posed Learning Problem – A computer program is said to learn from experience E in context to some task T and some performance measure P, if its performance on T, as was measured by P, upgrades with experience E. \n",
    "\n",
    "Any problem can be segregated as well-posed learning problem if it has three traits – \n",
    "\n",
    "Task\n",
    "Performance Measure \n",
    "Experience \n",
    "Certain examples that efficiently defines the well-posed learning problem are – \n",
    "\n",
    "1. To better filter emails as spam or not \n",
    "\n",
    "Task – Classifying emails as spam or not\n",
    "Performance Measure – The fraction of emails accurately classified as spam or not spam \n",
    "Experience – Observing you label emails as spam or not spam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A checkers learning problem\n",
    "Task – Playing checkers game \n",
    "Performance Measure – percent of games won against opposer\n",
    "Experience – playing implementation games against itself\n",
    "3. Handwriting Recognition Problem \n",
    "\n",
    "Task – Acknowledging handwritten words within portrayal \n",
    "Performance Measure – percent of words accurately classified\n",
    "Experience – a directory of handwritten words with given classifications\n",
    "4. A Robot Driving Problem \n",
    "\n",
    "Task – driving on public four-lane highways using sight scanners\n",
    "Performance Measure – average distance progressed before a fallacy\n",
    "Experience – order of images and steering instructions noted down while observing a human driver\n",
    "5. Fruit Prediction Problem\n",
    "\n",
    "Task – forecasting different fruits for recognition\n",
    "Performance Measure – able to predict maximum variety of fruits\n",
    "Experience – training machine with the largest datasets of fruits images\n",
    "6. Face Recognition Problem\n",
    "\n",
    "Task – predicting different types of faces\n",
    "Performance Measure – able to predict maximum types of faces\n",
    "Experience – training machine with maximum amount of datasets of different face images\n",
    "7. Automatic Translation of documents\n",
    "\n",
    "Task – translating one type of language used in a document to other language\n",
    "Performance Measure – able to convert one language to other efficiently\n",
    "Experience – training machine with a large dataset of different types of languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Question 5:Is machine learning capable of solving all problems? Give a detailed explanation of your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitation 1 — Ethics\n",
    "Machine learning, a subset of artificial intelligence, has revolutionalized the world as we know it in the past decade. The information explosion has resulted in the collection of massive amounts of data, especially by large companies such as Facebook and Google. This amount of data, coupled with the rapid development of processor power and computer parallelization, has now made it possible to obtain and study huge amounts of data with relative ease.\n",
    "It is easy to understand why machine learning has had such a profound impact on the world, what is less clear is exactly what its capabilities are, and perhaps more importantly, what its limitations are. Yuval Noah Harari famously coined the term ‘dataism’, which refers to a putative new stage of civilization we are entering in which we trust algorithms and data more than our own judgment and logic.\n",
    "Whilst you may find this idea laughable, remember the last time you went on vacation and followed the instructions of a GPS rather than your own judgment on a map — do you question the judgment of the GPS? People have literally driven into lakes because they blindly followed the instructions from their GPS.\n",
    "The idea of trusting data and algorithms more than our own judgment has its pros and cons. Obviously, we benefit from these algorithms, otherwise, we wouldn’t be using them in the first place. These algorithms allow us to automate processes by making informed judgments using available data. Sometimes, however, this means replacing someone’s job with an algorithm, which comes with ethical ramifications. Additionally, who do we blame if something goes wrong?\n",
    "The most commonly discussed case currently is self-driving cars — how do we choose how the vehicle should react in the event of a fatal collision? In the future will we have to select which ethical framework we want our self-driving car to follow when we are purchasing the vehicle?\n",
    "If my self-driving car kills someone on the road, whose fault is it?\n",
    "Whilst these are all fascinating questions, they are not the main purpose of this article. Clearly, however, machine learning cannot tell us anything about what normative values we should accept, i.e. how we should act in the world in a given situation. As David Hume famously said, one cannot ‘derive an ought from an is’.\n",
    "Limitation 2 — Deterministic Problems\n",
    "This is a limitation I personally have had to deal with. My field of expertise is environmental science, which relies heavily on computational modeling and using sensors/IoT devices.\n",
    "Machine learning is incredibly powerful for sensors and can be used to help calibrate and correct sensors when connected to other sensors measuring environmental variables such as temperature, pressure, and humidity. The correlations between the signals from these sensors can be used to develop self-calibration procedures and this is a hot research topic in my research field of atmospheric chemistry.\n",
    "However, things get a bit more interesting when it comes to computational modeling.\n",
    "Running computer models that simulate global weather, emissions from the planet, and transport of these emissions is very computationally expensive. In fact, it is so computationally expensive, that a research-level simulation can take weeks even when running on a supercomputer.\n",
    "Good examples of this are MM5 and WRF, which are numerical weather prediction models that are used for climate research and for giving you weather forecasts on the morning news. Wonder what weather forecasters do all day? Run and study these models.\n",
    "Running weather models is fine, but now that we have machine learning, can we just use this instead to obtain our weather forecasts? Can we leverage data from satellites, weather stations, and use an elementary predictive algorithm to discern whether it is going to rain tomorrow?\n",
    "The answer is, surprisingly, yes. If we have knowledge of the air pressures around a certain region, the levels of moisture in the air, wind speeds, and information about neighboring points and their own variables, it becomes possible to train, for example, a neural network. But at what cost?\n",
    "Using a neural network with a thousand inputs to determine whether it will rain tomorrow in Boston is possible. However, utilizing a neural network misses the entire physics of the weather system.\n",
    "Machine learning is stochastic, not deterministic.\n",
    "A neural network does not understand Newton’s second law, or that density cannot be negative — there are no physical constraints.\n",
    "However, this may not be a limitation for long. There are multiple researchers looking at adding physical constraints to neural networks and other algorithms so that they can be used for purposes such as this.\n",
    "Limitation 3 — Data\n",
    "This is the most obvious limitation. If you feed a model poorly, then it will only give you poor results. This can manifest itself in two ways: lack of data, and lack of good data.\n",
    "Lack of Data\n",
    "Many machine learning algorithms require large amounts of data before they begin to give useful results. A good example of this is a neural network. Neural networks are data-eating machines that require copious amounts of training data. The larger the architecture, the more data is needed to produce viable results. Reusing data is a bad idea, and data augmentation is useful to some extent, but having more data is always the preferred solution.\n",
    "If you can get the data, then use it.\n",
    "Lack of Good Data\n",
    "Despite the appearance, this is not the same as the above comment. Let’s imagine you think you can cheat by generating ten thousand fake data points to put in your neural network. What happens when you put it in?\n",
    "It will train itself, and then when you come to test it on an unseen data set, it will not perform well. You had the data but the quality of the data was not up to scratch.\n",
    "In the same way that having a lack of good features can cause your algorithm to perform poorly, having a lack of good ground truth data can also limit the capabilities of your model. No company is going to implement a machine learning model that performs worse than human-level error.\n",
    "Similarly, applying a model that was trained on a set of data in one situation may not necessarily apply as well to a second situation. The best example of this I have found so far is in breast cancer prediction.\n",
    "Mammography databases have a lot of images in them, but they suffer from one problem that has caused significant issues in recent years — almost all of the x-rays are from white women. This may not sound like a big deal, but actually, black women have been shown to be 42 percent more likely to die from breast cancer due to a wide range of factors that may include differences in detection and access to health care. Thus, training an algorithm primarily on white women adversely impacts black women in this case.\n",
    "What is needed in this specific case is a larger number of x-rays of black patients in the training database, more features relevant to the cause of this 42 percent increased likelihood, and for the algorithm to be more equitable by stratifying the dataset along the relevant axes.\n",
    "If you are skeptical of this or would like to know more, I recommend you look at this article.\n",
    "Limitation 4 — Misapplication\n",
    "Related to the second limitation discussed previously, there is purported to be a “crisis of machine learning in academic research” whereby people blindly use machine learning to try and analyze systems that are either deterministic or stochastic in nature.\n",
    "For reasons discussed in limitation two, applying machine learning on deterministic systems will succeed, but the algorithm which not be learning the relationship between the two variables, and will not know when it is violating physical laws. We simply gave some inputs and outputs to the system and told it to learn the relationship — like someone translating word for word out of a dictionary, the algorithm will only appear to have a facile grasp of the underlying physics.\n",
    "For stochastic (random) systems, things are a little less obvious. The crisis of machine learning for random systems manifests itself in two ways:\n",
    "P-hacking\n",
    "Scope of the analysis\n",
    "P-hacking\n",
    "When one has access to large data, which may have hundreds, thousands, or even millions of variables, it is not too difficult to find a statistically significant result (given that the level of statistical significance needed for most scientific research is p < 0.05). This often leads to spurious correlations being found that are usually obtained by p-hacking (looking through mountains of data until a correlation showing statistically significant results is found). These are not true correlations and are just responding to the noise in the measurements.\n",
    "This has resulted in individuals ‘fishing’ for statistically significant correlations through large data sets, and masquerading these as true correlations. Sometimes, this is an innocent mistake (in which case the scientist should be better trained), but other times, it is done to increase the number of papers a researcher has published — even in the world of academia, competition is strong and people will do anything to improve their metrics.\n",
    "Scope of the Analysis\n",
    "There are inherent differences in the scope of the analysis for machine learning as compared with statistical modeling — statistical modeling is inherently confirmatory, and machine learning is inherently exploratory.\n",
    "We can consider confirmatory analysis and models to be the kind of thing that someone does in a Ph.D. program or in a research field. Imagine you are working with an advisor and trying to develop a theoretical framework to study some real-world system. This system has a set of pre-defined features that it is influenced by, and, after carefully designing experiments and developing hypotheses you are able to run tests to determine the validity of your hypotheses.\n",
    "Exploratory, on the other hand, lacks a number of qualities associated with the confirmatory analysis. In fact, in the case of truly massive amounts of data and information, the confirmatory approaches completely break down due to the sheer volume of data. In other words, it simply is not possible to carefully lay out a finite set of testable hypotheses in the presence of hundreds, much less thousands, much less millions of features.\n",
    "Therefore and, again, broadly speaking, machine learning algorithms and approaches are best suited for exploratory predictive modeling and classification with massive amounts of data and computationally complex features. Some will contend that they can be used on “small” data but why would one do so when classic, multivariate statistical methods are so much more informative?\n",
    "ML is a field which, in large part, addresses issues derived from information technology, computer science, and so on, these can be both theoretical and applied problems. As such, it is related to fields such as physics, mathematics, probability, and statistics but ML is really a field unto itself, a field which is unencumbered by the concerns raised in the other disciplines. Many of the solutions ML experts and practitioners come up with are painfully mistaken…but they get the job done.\n",
    "Limitation 5 — Interpretability\n",
    "Interpretability is one of the primary problems with machine learning. An AI consultancy firm trying to pitch to a firm that only uses traditional statistical methods can be stopped dead if they do not see the model as interpretable. If you cannot convince your client that you understand how the algorithm came to the decision it did, how likely are they to trust you and your expertise?\n",
    "As bluntly stated in “Business Data Mining — a machine learning perspective”:\n",
    "“A business manager is more likely to accept the [machine learning method] recommendations if the results are explained in business terms”\n",
    "These models as such can be rendered powerless unless they can be interpreted, and the process of human interpretation follows rules that go well beyond technical prowess. For this reason, interpretability is a paramount quality that machine learning methods should aim to achieve if they are to be applied in practice.\n",
    "The blossoming -omics sciences (genomics, proteomics, metabolomics and the like), in particular, have become the main target for machine learning researchers precisely because of their dependence on large and non-trivial databases. However, they suffer from the lack of interpretability of their methods, despite their apparent success.\n",
    "Summary and Peter Voss’ List\n",
    "While it is undeniable that AI has opened up a wealth of promising opportunities, it has also led to the emergence of a mindset that can be best described as “AI solutionism”. This is the philosophy that, given enough data, machine learning algorithms can solve all of humanity’s problems.\n",
    "As I hope I have made clear in this article, there are limitations that, at least for the time being, prevent that from being the case. A neural network can never tell us how to be a good person, and, at least for now, do not understand Newton’s laws of motion or Einstein’s theory of relativity. There are also fundamental limitations grounded in the underlying theory of machine learning, called computational learning theory, which are primarily statistical limitations. We have also discussed issues associated with the scope of the analysis and the dangers of p-hacking, which can lead to spurious conclusions. There are also issues with the interpretability of results, which can negatively impact businesses that are unable to convince clients and investors that their methods are accurate and reliable.\n",
    "Whilst in this article I have covered very broadly some of the most important limitations of AI, to finish, I will outline a list published in an article by Peter Voss in October 2016, outlining a more comprehensive list on the limitations of AI. Whilst current mainstream techniques can be very powerful in narrow domains, they will typically have some or all of a list of constraints that he sets out and which I’ll quote in full here:\n",
    "Each narrow application needs to be specially trained\n",
    "Require large amounts of hand-crafted, structured training data\n",
    "Learning must generally be supervised: Training data must be tagged\n",
    "Require lengthy offline/ batch training\n",
    "Do not learn incrementally or interactively, in real-time\n",
    "Poor transfer learning ability, reusability of modules, and integration\n",
    "Systems are opaque, making them very hard to debug\n",
    "Performance cannot be audited or guaranteed at the ‘long tail’\n",
    "They encode correlation, not causation or ontological relationships\n",
    "Do not encode entities or spatial relationships between entities\n",
    "Only handle very narrow aspects of natural language\n",
    "Not well suited for high-level, symbolic reasoning or planning\n",
    "All that being said, machine learning and artificial intelligence will continue to revolutionize industry and will only become more prevalent in the coming years. Whilst I recommend you utilize machine learning and AI to their fullest extent, I also recommend that you remember the limitations of the tools you use — after all, nothing is perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6:Can you explain the various forms of supervised learning? Explain each one with an example\n",
    "application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification : It is a Supervised Learning task where output is having defined labels(discrete value). For example in above Figure A, Output – Purchased has defined labels i.e. 0 or 1 ; 1 means the customer will purchase and 0 means that customer won’t purchase. The goal here is to predict discrete values belonging to a particular class and evaluate on the basis of accuracy.\n",
    "It can be either binary or multi class classification. In binary classification, model predicts either 0 or 1 ; yes or no but in case of multi class classification, model predicts more than one class.\n",
    "Example: Gmail classifies mails in more than one classes like social, promotions, updates, forum.\n",
    "Regression : It is a Supervised Learning task where output is having continuous value.The goal here is to predict a value as much closer to actual output value as our model can and then evaluation is done by calculating error value. The smaller the error the greater the accuracy of our regression model.Example:Predicting the price of a building based on various factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7:Describe the machine learning process in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine a dataset as a table, where the rows are each observation (aka measurement, data point, etc), and the columns for each observation represent the features of that observation and their values.\n",
    "\n",
    "At the outset of a machine learning project, a dataset is usually split into two or three subsets. The minimum subsets are the training and test datasets, and often an optional third validation dataset is created as well.\n",
    "\n",
    "Once these data subsets are created from the primary dataset, a predictive model or classifier is trained using the training data, and then the model’s predictive accuracy is determined using the test data.\n",
    "\n",
    "As mentioned, machine learning leverages algorithms to automatically model and find patterns in data, usually with the goal of predicting some target output or response. These algorithms are heavily based on statistics and mathematical optimization.\n",
    "\n",
    "Optimization is the process of finding the smallest or largest value (minima or maxima) of a function, often referred to as a loss, or cost function in the minimization case. One of the most popular optimization algorithms used in machine learning is called gradient descent, and another is known as the the normal equation.\n",
    "\n",
    "In a nutshell, machine learning is all about automatically learning a highly accurate predictive or classifier model, or finding unknown patterns in data, by leveraging learning algorithms and optimization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
